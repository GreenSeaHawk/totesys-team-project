Star schemas:    
    -Sales_schema
        -fact_sales_order
        -dim_counterparty
        -dim_currency
        -dim_date
        -dim_design
        -dim_location
        -dim_staff
    -Purchases_schema
        -fact_purchase_order
        -dim_counterparty
        -dim_currency
        -dim_date
        -dim_location
        -dim_staff
    - Payments schema
        -fact_payment
        -dim_counterparty
        -dim_currency
        -dim_date
        -dim_payment_type
        -dim_transaction
        
Processed zone bucket layout:
    -last_run
    -fact_sales_order
    -fact_purchase_order
    -fact_payment
    -dim_counterparty
    -dim_currency
    -dim_date
    -dim_location
    -dim_staff
    -dim_design
    -dim_payment_type
    -dim_transaction



store a timestamp of when the lambda function was last run ins Prccessed zone bucket:
    last_run = yy:mm:dd:hh:mm

##############################################################################################################################################################################################################################################################################################################################################################################
                                                    Collect data from ingestion bucket:
 ##############################################################################################################################################################################################################################################################################################################################################################################
    dim_counterparty:
        collect data from counterparty folder in ingestion zone
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='counterparty/')
            counterparty_data = get_data_from_files(Bucket=IngestionBucket, filenames)
        
        counterparty_data is a list of dictionaries that look like this:
            {
                counterparty_id:int
                counterparty_legal_name:str
                legal_adress_id:int #refrences address table
                commecial_contact:str
                delivary_contact:str
                created_at:timestamp
                last_updated_at:timestamp
            }
        its needs to be converted to list of dictionaries that look like this:
            {
                counterparty_id:int
                counterparty_legal_name:str
                counterparty_legal_address_line_1:str
                counterparty_legal_address_line_2:str
                counterparty_legal_district:str 
                counterparty_legal_city:str
                counterparty_legal_country:str
                counterparty_legal_phone_number:str
            }
        Need to write code to transform the data
 #########################################################################################################################################################################################################    
    dim_currency:
        collect data from currency folder in ingestion zone
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='currency/')
            currency_data = get_data_from_files(Bucket=IngestionBucket, filenames)
        
        currency_data is a list of dictionaries that look like this:
            {
                currency_id:int
                currency_code:str
                created_at:timestamp
                last_updated_at:timestamp
            }
        its needs to be converted to list of dictionaries that look like this:
            {
                currency_id:int
                currency_code:str
                currency_name:str
            }
        Need to write code to transform the data
 #########################################################################################################################################################################################################     
    dim_date:
        we have 2 options:
        -create delivery dates from scratch, making a date starting at the first date in the db and adding to the date every day:
            much easier to code 
            lambda fucntion will spend less time executing:
            size of dim_dates will be much larger than other option

        -search the db for all dates used, only make rows for delivary dates used in the db 
            size of table will be consdierably smaller 
            much more difficult to code
            dates are located in:
                purchase_order: agreed_delivery_date, agreed_payment_date
                sales_order: agreed_delivery_date, agreed_payment_date
                payment: payment date
        dim_dates structure:
            {
                date_id:int
                year:int
                month:int
                day:int
                day_of_week:int
                day_name:str
                month_name:str
                quater int
            }
        Need to write code to transform the data
    
#########################################################################################################################################################################################################     
    dim_location:
        collect data from address folder in ingestion bucket:
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='address/')
            location_data = get_data_from_files(Bucket=IngestionBucket, filenames)

            location_data before any transformation:
                {
                    address_id:int
                    address_line_1:str
                    address_line_2:str
                    district:str
                    city:str
                    postal_code:str 
                    country:str
                    phone: str
                    created_at:timestamp
                    last_updated:str
                    }
            needs to transform into dim_lcoation:
                {
                    location_id:int
                    address_line_1:str
                    address_line_2:str
                    district:str
                    city:str
                    postal_code:str
                    country:str
                    phone:str
                }
            To transform the data:
                transformed_location_data=[]
                for row in location_data:
                    temp_dict = {
                        location_id:    row["address_id"]
                        address_line_1: row["address_line"]
                        address_line_2: row["address_line_2"]
                        district:       row["district"]
                        city:           row["address_id"]
                        postal_code:    row["postal_code"]
                        country:        row["country"]
                        phone:          row["phone"]
                    }
                    transformed_location_data.append(temp_dict)
            
            then write it into the file dim_location:
                add_to_s3_file(TransformedBucket, dim_location.json, transformed_location_data)
#########################################################################################################################################################################################################  
    dim_staff:
        collect data from staff folder in ingestion bucket:
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='staff/')
            staff_data = get_data_from_files(Bucket=IngestionBucket, filenames)
        
        Transfrom data from this:
            {
                staff_id:int
                first_name:str
                last_name:str
                department_id:int
                email_adrress:str
                created_at:timestamp
                last_updated:timestamp
            }
        into this:
            {
                staff_id:int
                first_name:str
                last_name:str
                department_name:str
                location:str
                email_adrress:str
            }
        Need to write code to transform
#######################################################################################################################################################################################
    dim_design:
        collect data from design folder in ingestion bucket:
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='design/')
            design_data = get_data_from_files(Bucket=IngestionBucket, filenames)

        Transform data from this:
            {
                design_id: int
                created_at:timestamp
                last_updated:timestamp
                design_name:str
                file_location:str
                file_name:str
            }
            to this:
            {
                design_id:int
                design_name:str
                file_location
                file_name
            }

            transformed_design_data=[]
            for row in design_data:
                temp_dict = {
                    design_id:row[design_id]
                    design_name:row[design_name]
                    file_location:row[file_location]
                    file_name:row[file_name]
                }
                transformed_design_data.append(temp_dict)

        Upload transformed data to s3 bucket:
            add_to_s3_file(TransformedBucket, dim_design.json, transformed_design_data)
#########################################################################################################################################################################################################
    dim_payment_type:
        collect data from payment_type folder in ingestion bucket:
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='payment_type/')
            design_data = get_data_from_files(Bucket=IngestionBucket, filenames)

        Transform data from this:
            {
                payment_type_id: int 
                payment_type_name: str 
                created_at: str
                last_updated: str
            }
            to this:
            {
                payment_type_id: int 
                payment_type_name: str 
            }
            
            transformed_payment_type_data=[]
            for row in payment_type_data:
                temp_dict = {
                    payment_type_id: row[payment_type_id] 
                    payment_type_name: row[payment_type_name]
                }
                transformed_payment_type_data.append(temp_dict)
        
        Upload transformed data to s3 bucket:
            add_to_s3_file(TransformedBucket, dim_payment_type.json, transformed_payment_type_data)
#########################################################################################################################################################################################################
    dim_transaction:
    collect data from transcation folder in ingestion bucket:
            filenames = list_all_filenames_in_s3(Bucket==IngestionBucket, prefix='transcation/')
            transaction_data = get_data_from_files(Bucket=IngestionBucket, filenames)

            Transform data from this:
            {
                payment_type_id: int 
                payment_type_name: str 
                created_at: str
                last_updated: str
            }
            to this:
            {
                payment_type_id: int 
                payment_type_name: str 
            }

            need to transform from this into this:
#########################################################################################################################################################################################################



            


def list_all_filenames_in_s3(Bucket, prefix=''):
'''Find the names of all files in S3 bucket, which are newer than than last_ran'''
    s3_client = boto3.client('s3')
    paginator = s3_client.get_paginator('list_objects_v2')
    pages = paginator.paginate(Bucket=Bucket, Prefix=prefix)
    
    filenames = []  # List to store all file names
    
    for page in pages:
        if 'Contents' in page:
            for obj in page['Contents']:
                if obj['key'](exctract date from this) > last_run
                filenames.append(obj['Key'])  # Add each file's key (file name) to the list
    
    return filenames


def get_data_from_files(Bucket,filnames):
    '''Get the data in all files and store them in one variable'''
    big_data = []
            for file in filenames:
                response = s3.get_object(Bucket=IngestionBucket Key=file)
                data = json.load(response["body"])
                big_data.append(data)
                big_data list(set(big_data)) # to remove duplicates
                return big_data



def add_to_s3_file(Bucket, Key, additional_content):
    s3_client = boto3.client('s3')
    
    # Step 1: Download the existing file content
    response = s3_client.get_object(Bucket=bucket_name, Key=key)
    existing_content = json.load(response["body"])
    
    # Step 2: Add new content to the existing content
    updated_content = existing_content + additional_content
    
    # Step 3: Upload the updated content back to S3
    s3_client.put_object(Bucket=bucket_name, Key=key, Body=updated_content)
        
